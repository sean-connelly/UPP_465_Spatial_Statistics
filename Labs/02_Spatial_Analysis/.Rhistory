# Here we examine only schools within the buffer.  For schools within one mile of a toxic site calculate an index of exposure to toxic emissions. For each school, find all toxic sites within 1 mile, divide the siteâs toxic score by its distance to the school, then sum over all toxic sites to create a âtoxic indexâ for the school.
##############
# Part 1: Solution
##############
#Compare the demographic characteristics of the ten schools with highest toxic index (âTopTenâ schools) to the demographic characteristics of all others within the one mile buffer
# Is there a higher proportion of  economically disadvantaged or minority racial groups  in the top ten schools  (and thus potentially more exposed to pollution) compared to the proportion in  other schools within the one mile buffer?
# On a map show:
# Toxic sites, schools and highways
# for the top ten schools only, draw a symbol proportional to the schoolâs exposure index
# The coordinate system for all spatial data is:
# NAD_1983_StatePlane_Texas_North_Central_FIPS_4202_Feet
# North American Datum 1983
# State Plane Coordinate System (SPCS), Texas North Central Zone
# (Federal Information Processing Standard Code (FIPS) 4202)
# Measurement units are feet. There are 5280 feet in one mile.
#Data key for the variables in the school data:
# # # Economically disadvantaged (n_lowInc)
# # # African American (n_black)
# # # Hispanic (n_hispanic)
# # # Asian (n_asian)
# # # White (n_white)
# # # Total student body (n_all).
#Note that the components may not add up to the total as some are not mutually exclusive categories.
########################################################
#make sure the below libraries are installed on your machine. Use install.packages("LIBRARYNAME")
rm(list=ls()) #clear objects in memory
# Set working directory
setwd(paste0(here::here(), "/02_Spatial_Analysis"))
########################################################
# Load additional libraries
pacman::p_load(tidyverse, # for basic data manipulation, visualization
patchwork, # for arranging ggplots in grids
sf, # simple features for spatial
summarytools, # for checking data frame characteristics
here, # for relative file paths
janitor) # for cleaning and tabulations
#load your spatial libraries
library(sp)
library(raster)
library(spatstat)
library(rgdal)
library(maptools)
library(rgeos)
library(GISTools)
library(shapefiles)
########################################################
#read in the shapefiles from your working director. Need the raster library to use the shapefile("...") command.
# Read in shapefiles as simple features objects
sch <- st_read("Raw_Data/Dal_schools.shp")#contains all schools in Dallas county
tox <- st_read("Raw_Data/Dal_toxic.shp")#contains all toxic sites in Dallas
hwy <- st_read("Raw_Data/Highways_NCTCOG_SPCS.shp")#highways
cnty <- st_read("Raw_Data/County_NCTCOG.shp")#county boundary
########################################################
#explore and plot the shapefiles
#explore the data
head(cnty, 8)
head(tox)
head(sch)
str(sch) #another way to look at the structure of your data
#summarize the data
summary(cnty)
summary(sch)
summary(tox)
#plot your data
ggplot() +
geom_sf(data = cnty, color = "grey") +
geom_sf(data = hwy, color = "brown") +
geom_sf(data = sch, color = "blue") +
geom_sf(data = tox, color = "red") +
theme_void()
########################################################
#Since our school and tox data are only in Dallas county, lets only subset use that part of the shape file. You can subset in the same way you create subsets from data.frame objects.
dallas <- cnty %>%
filter(COUNTY == "Dallas")
#plot your data
ggplot() +
geom_sf(data = cnty, color = "black", fill = "white") +
geom_sf(data = dallas, color = "orange", fill = "white") +
geom_sf(data = hwy, color = "light grey") +
geom_sf(data = sch, color = "blue") +
geom_sf(data = tox, color = "red") +
geom_sf_text(data = cnty, aes(label = COUNTY), color = "black") +
theme_void()
#####try subsetting Tarrant County and plotting it.
ggplot() +
geom_sf(data = cnty, color = "black", fill = "white") +
geom_sf(data = cnty %>% filter(COUNTY == "Tarrant"), color = "orange", fill = "white") +
geom_sf(data = hwy, color = "light grey") +
geom_sf(data = sch, color = "blue") +
geom_sf(data = tox, color = "red") +
geom_sf_text(data = cnty, aes(label = COUNTY), color = "black") +
theme_void()
#-----------------------------------------------------------------------------------
##############A small detour on projections
#-----------------------------------------------------------------------------------
#Read the accompanyin pdf uploaded to blackboard 'Overview of Coordinate Reference Systems (CRS)' in R
# (also available here: #https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/OverviewCoordinateReferenceSystems.pdf (also on blackboard)
head(tox)
summary(tox)
#UNPROJECTED GEOGRAPHIC COORDINATE SYSTEMS
#WGS84<-CRS("+init=epsg:4326")   WGS84 (EPSG: 4326)
#NAD83<-CRS("+init=epsg:4326")   NAD83 (EPSG:4269)
#NAD27<-CRS("+init=epsg:4267")   NAD27 (EPSG:4267)
#If all you have is lat/long data, and if you know the datum (commonly one of the three above in the U.S.), then you can specify the coordinates and the projection using the above code. An example is given below (lines 126-141)
#Other coordinate systems can also be specificed
#TX4202<-CRS("+init=esri:102738") NAD 1983 StatePlane Texas North Central FIPS 4202 Feet
#To look up the code for a specific projection, search in the followin website. Browse to http://spatialreference.org and find the State Plane Coordinate System for North Eastern Illinois.
#########################################
#what would you do if you only had lat/long data? The following code walks you through reading a lat/long data and defining it as a spatial data obejected that is properly projected.
u<-as.data.frame(tox)#Start by creating a new object u that is a data frame. Use the tox object
head(u)#view the file
u<-u[,-c(6:7)]#remove the 6th and 7th columns (the -c(6:7) tells R to remove the 6th and 7th columns. This code say replace u with an object after removin column 6 and 7)
head(u)#see the new u
class(u)#look at class of u. It is a data frame. If is as if you just read a csv file with latitude and longitude data.
#plotting geographic cooridnates
plot(u$LONGDD,u$LATDD)#R tries to fill up the plotting area so there will be distortions
plot(u$LONGDD,u$LATDD,asp=1:1)#use a 1:1 aspect ratio so same scale is used vertically and horizontally. Better.
###########LET'S CONVERT U INTO A SPATIAL POINTS DATAFRAME.
#1. To let R know what you have is spatial data, what you have to specify is the coordinates for the data. The sp library is required.
#specify the coordinates to convert to class SpatialPointsDataFrame
?coordinates
class(u)
coordinates(u)<- ~LONGDD + LATDD #it will look for these variables (LONGDD and LATDD) in the u (the data frame)
class(u)
plot(u)
summary(u)#note that there is no projection defined currently
projection(u)<-CRS("+init=epsg:4326") #let it know to use WGS84 datum. If another datum was used, you would have to specify that.
summary(u)#Note that Is projected=FALSE in the summary output
#do u and school (sch) line up?
plot(u)
#let's plot the schools over the toxic sites
plot(sch,col=2,add=TRUE)# if we try to add the schools to the plot, they will not show up in the window since they have a different projection.
#Compare the projections of the two spatial objects
compareCRS(u,sch)
compareCRS(u,tox)
compareCRS(sch,tox)
summary(tox)
#2.
#project your data using spTransform
#look up the coordinate system you want or use the one from an existing data
#Project u in the State Plane Coordinate system (look this up at http://spatialreference.org)
u2<-spTransform(u,CRS("+init=esri:102738"))#alternately, TX4202<-CRS("+init=esri:102738"); u2<-spTransform(u,TX4202) ; summary(u2)
plot(u2)
plot(sch,col=2,add=TRUE)
projection(sch)
compareCRS(u2,sch)
##################Alternately, you could just ask R to project u using the projection from the tox or sch file.
u3<-spTransform(u,projection(tox))
plot(sch,col=3)
plot(u3,col=2,add=TRUE)
compareCRS(u3,sch)
#########################################
#END PROJECTIONS DETOUR
#-----------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------
##################################################################################
#########################################
#Get back to our problem
#lets remove parts of our data we will not need:
dallas <- cnty %>% filter(COUNTY == "Dallas")
plot(dallas[1])
plot(tox,cex=.5,col=2,add=TRUE)#cex size of markers, col color, pch type of symbols (play arround with these options to settle on what you like)
plot(sch,cex=.4,col=3,add=TRUE)#plot sch
plot(hwy,col=8,add=TRUE)#plot hwy
############################################
#Lets remove parts of our the highway network outside of Dallas
# ??gIntersection  frome rgeos library
hwy2 <- st_intersection(hwy, dallas)
plot(dallas[1]) # looks cleaner, but not a necessary step for our analysis.
plot(hwy2[1],col=8, add=TRUE)
############################################
############################################-----------------
#The first question is wheter schools within a 1 mile buffer of toxic sites are demographically the same as those outside
#how would you go about doing this? We would neet to create 1 mile buffer around the toxic sites.
#let's create a buffer
tox_buf <- st_buffer(tox, dist = 5280) # create an object tox_buf that has a radius of 5280 ft. Why do we use 5280? 1mi=5280 ft. The units of our projection are feet (see summary(tox)).
summary(tox)#see the units of the projection.
plot(tox_buf[1])
plot(tox,add=TRUE)
head(tox_buf)
class(tox_buf)# its a polygon file retaining all aspects of the tox sites on the buffers.
#find the schools that fall in the buffer zones. This works the same way as subseting. Just as data[1:5,] gives you the first 5 rows of a data, data[buffer,] gives you the data that falls inside the buffer
sch_1tox <- st_filter(sch, tox_buf) #sch_1tox contains only the schools in the buffer
dim(sch)
dim(sch_1tox) #Look at the dimensions of the data. There are 94 schools in the toxic 1 mile buffer
plot(sch_1tox)# plots only the 94 schools affected
names(sch)
plot(tox_buf,add=TRUE,border=8)
#create a separate data for the schools outside of the buffer
#note that:
ggplot() +
geom_sf(data = tox_buf, fill = "red") +
geom_sf(data = sch) +
geom_sf(data = sch_1tox, color = "green")
sch_1tox$ORG_NUM#is the unique IDs for the schools in the 1 mile buffer
sch$ORG_NUM# are the unique IDs for all schools.
sch$ORG_NUM %in% sch_1tox$ORG_NUM# returns TRUE for schools in sch that are also in sch_1tox
!sch$ORG_NUM %in% sch_1tox$ORG_NUM# takes the negation of the above (returns FALSE where the above was TRUE, returns TRUE where the above was false)
#in other words, it returs true for schools that are not in the 1 mile toxic buffer (sch_1tox). See simple example below.
#list1 %in% list2
##----------------
#Subsetting example ...
#example ....
c(3,4,5,6,7) %in% c(5,6)#returs TRUE for list1 items that are in list2
!c(3,4,5,6,7) %in% c(5,6)#does the opposite
c(3,4,5,6,7)[c(3,4,5,6,7) %in% c(5,6)]#subsets list1 that are in list2
c(3,4,5,6,7)[!c(3,4,5,6,7) %in% c(5,6)]#subset list1 that are not in list2
##----------------
#lets apply that to the tox data
sch_o1tox<-sch[!sch$ORG_NUM %in% sch_1tox$ORG_NUM,] # the comma before ] is needed becuase you are subsetting a data frame that has two dimensions. For vectors, you wouldn't need it as in the numeric example anove.
dim(sch_o1tox)#look at the dimensions. 376 schools are outside of the buffers
plot(sch_o1tox,col=3,add=TRUE)
plot(tox_buf,add=TRUE)
test <- sch %>%
mutate("tox_status" = )
############################################
#We now have two data sets for the in buffer and out of buffer data. I will create a data.frame for each for ease of manipulation.
#compare the sociodemographics of the two groups of schools
d1<-as.data.frame(sch_1tox)#schools in buffer
d2<-as.data.frame(sch_o1tox)#schools outside of buffer
#note the missing values
#I will treat missingness as missing at random and exclude these observations from the data.
d1<-na.omit(d1)#creates a data d1 without the missing values in d1.
d2<-na.omit(d2)#creates a data d1 without the missing values in d2.
dim(d1)
dim(d2)
summary(d1)#the summary shows that somme of the school demographic data is missing (NA is missing)
summary(d2)
head(d1)#see the first few rows of d1
#We are interested in comparing the values in columns 5-10 in each data set.
#Take the total sum of students in each column and compare proportions of students in and outside of the buffer.
apply(d1[,5:10],2,sum)#takes data d1 columns 5 through 10, and by column (2 tells it to do the operation by column), applies the sum function. If you had wanted the operation to be done by row, you would use 1 instead of 2.
apply(d2[,5:10],2,sum)
#Create a new data frame with these two results, usin each result as a row.
# rbind(c(1,2,3),c(4,5,6))#run this code to see what rbind does
# data.frame(rbind(c(1,2,3),c(4,5,6)))#run this code to see what data.frame does
#create a data frame with each row correspondeing to in
t1<-data.frame(rbind(
apply(d1[,5:10],2,sum),
apply(d2[,5:10],2,sum)
))
##
t1#see t1
row.names(t1)<-c("in_buffer","outside_buffer")#create row names for the data
t1
#names(t1)<-c("All","Black","LowIncome","Hispanic","Asian","White")#update the column names with more intuitive names
#t1
#lets get the column totals for total student in each group.
coltot<-apply(t1,2,sum)
#Transpose the t1 data
t(t1)#transposes t1 (makes the rows into columns)
#Divide the transposed data by coltot (if you don't transpose, the dividsion will not work. Try it and see the results). YOu cal also just copy t1 to a spreadsheet and compute the percentages.
t(t1)/coltot
#the above output gives us the percentaes of each category that is in and outside of the toxic buffer. 18.6% of all students are in the buffer. 13.0% of black students are in the buffer. As compared to all studenst, black students tend to be less likely to be in the toxic buffer. If we look at the Hispanic student proportion, 24.6% are in the buffer as compared to 18.6% for all studnets. It suggests that Hispanc students tend to be within these buffers more so than other students. We can more formally test these using a Chi-squared test.
#let's define some additional columns
t1$n_other<-t1$n_all-t1$n_black-t1$n_white-t1$n_asian#other_race
t1$n_nonHispanic<-t1$n_all-t1$n_hispanic#hispanic/non-hispanic
t1$n_nonLowInc<-t1$n_all-t1$n_lowInc#lowincome/non-lowincome
t1#see t1
#lets define three contingency tables
tRace<-t1[,c(2,5,6,7)]#table in/out buffer BY Race
tHisp<-t1[,c(4,8)]#table in/out buffer BY ethnicity/Hispanic
tEcon<-t1[,c(3,9)]#table in/out buffer BY Income
#let's check we have the correct columns
tRace
tHisp
tEcon
test <- sch %>%
mutate("tox_status" = st_intersects(., tox_buf))
View(test)
sch %>%
mutate("tox_status" = st_intersects(., tox_buf)) %>%
tabyl(tox_status)
sch %>%
mutate("tox_status" = st_intersects(., tox_buf)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
sch %>%
mutate("tox_status" = st_intersects(., tox_buf)) %>%
mutate(tox_status = ifelse(!is.na(tox_status), TRUE, FALSE)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
sch %>%
st_join(., tox_buf)
sch %>%
st_join(., tox_buf %>% select(SCORE)) %>%
mutate("tox_status" = ifelse(!is.na(SCORE), TRUE, FALSE)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
sch %>%
st_join(., tox_buf %>% select(SCORE))
sch %>%
st_join(., tox_buf %>% dplyr::select(SCORE)) %>%
mutate("tox_status" = ifelse(!is.na(SCORE), TRUE, FALSE)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
sch %>%
st_join(., tox_buf %>% dplyr::select(SCORE), left = TRUE)
sch %>%
st_join(., tox_buf %>% dplyr::select(SCORE), left = TRUE) %>%
mutate("tox_status" = ifelse(!is.na(SCORE), TRUE, FALSE)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
sch %>%
st_join(., tox_buf %>% dplyr::select(SCORE), left = TRUE, join = st_intersects) %>%
mutate("tox_status" = ifelse(!is.na(SCORE), TRUE, FALSE)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
sch %>%
st_join(., tox_buf %>% dplyr::select(SCORE), left = TRUE, join = st_within) %>%
mutate("tox_status" = ifelse(!is.na(SCORE), TRUE, FALSE)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
test <- sch %>%
st_join(., tox_buf %>% dplyr::select(SCORE), left = FALSE, join = sf::st_within)
ggplot() +
geom_sf(data = tox_buf, fill = "red") +
geom_sf(data = sch) +
geom_sf(data = sch_1tox, color = "green") +
geom_sf(data = test, color = "orange")
View(test)
sch %>%
mutate("tox_status" = ifelse(lengths(st_intersects(., tox_buf)) > 0, TRUE, FALSE)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
head(tox)
summary(tox)
#UNPROJECTED GEOGRAPHIC COORDINATE SYSTEMS
#WGS84<-CRS("+init=epsg:4326")   WGS84 (EPSG: 4326)
#NAD83<-CRS("+init=epsg:4326")   NAD83 (EPSG:4269)
#NAD27<-CRS("+init=epsg:4267")   NAD27 (EPSG:4267)
#If all you have is lat/long data, and if you know the datum (commonly one of the three above in the U.S.), then you can specify the coordinates and the projection using the above code. An example is given below (lines 126-141)
#Other coordinate systems can also be specificed
#TX4202<-CRS("+init=esri:102738") NAD 1983 StatePlane Texas North Central FIPS 4202 Feet
#To look up the code for a specific projection, search in the followin website. Browse to http://spatialreference.org and find the State Plane Coordinate System for North Eastern Illinois.
#########################################
#what would you do if you only had lat/long data? The following code walks you through reading a lat/long data and defining it as a spatial data obejected that is properly projected.
u<-as.data.frame(tox)#Start by creating a new object u that is a data frame. Use the tox object
head(u)#view the file
u<-u[,-c(6:7)]#remove the 6th and 7th columns (the -c(6:7) tells R to remove the 6th and 7th columns. This code say replace u with an object after removin column 6 and 7)
head(u)#see the new u
class(u)#look at class of u. It is a data frame. If is as if you just read a csv file with latitude and longitude data.
#plotting geographic cooridnates
plot(u$LONGDD,u$LATDD)#R tries to fill up the plotting area so there will be distortions
plot(u$LONGDD,u$LATDD,asp=1:1)#use a 1:1 aspect ratio so same scale is used vertically and horizontally. Better.
###########LET'S CONVERT U INTO A SPATIAL POINTS DATAFRAME.
#1. To let R know what you have is spatial data, what you have to specify is the coordinates for the data. The sp library is required.
#specify the coordinates to convert to class SpatialPointsDataFrame
?coordinates
class(u)
coordinates(u)<- ~LONGDD + LATDD #it will look for these variables (LONGDD and LATDD) in the u (the data frame)
class(u)
plot(u)
summary(u)#note that there is no projection defined currently
projection(u)<-CRS("+init=epsg:4326") #let it know to use WGS84 datum. If another datum was used, you would have to specify that.
summary(u)#Note that Is projected=FALSE in the summary output
#do u and school (sch) line up?
plot(u)
#let's plot the schools over the toxic sites
plot(sch,col=2,add=TRUE)# if we try to add the schools to the plot, they will not show up in the window since they have a different projection.
#Compare the projections of the two spatial objects
compareCRS(u,sch)
compareCRS(u,tox)
compareCRS(sch,tox)
summary(tox)
#2.
#project your data using spTransform
#look up the coordinate system you want or use the one from an existing data
#Project u in the State Plane Coordinate system (look this up at http://spatialreference.org)
u2<-spTransform(u,CRS("+init=esri:102738"))#alternately, TX4202<-CRS("+init=esri:102738"); u2<-spTransform(u,TX4202) ; summary(u2)
plot(u2)
plot(sch,col=2,add=TRUE)
projection(sch)
compareCRS(u2,sch)
##################Alternately, you could just ask R to project u using the projection from the tox or sch file.
u3<-spTransform(u,projection(tox))
plot(sch,col=3)
plot(u3,col=2,add=TRUE)
compareCRS(u3,sch)
#########################################
#END PROJECTIONS DETOUR
#-----------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------
##################################################################################
#########################################
#Get back to our problem
#lets remove parts of our data we will not need:
dallas <- cnty %>% filter(COUNTY == "Dallas")
plot(dallas[1])
plot(tox,cex=.5,col=2,add=TRUE)#cex size of markers, col color, pch type of symbols (play arround with these options to settle on what you like)
plot(sch,cex=.4,col=3,add=TRUE)#plot sch
plot(hwy,col=8,add=TRUE)#plot hwy
############################################
#Lets remove parts of our the highway network outside of Dallas
# ??gIntersection  frome rgeos library
hwy2 <- st_intersection(hwy, dallas)
plot(dallas[1]) # looks cleaner, but not a necessary step for our analysis.
plot(hwy2[1],col=8, add=TRUE)
############################################
############################################-----------------
#The first question is wheter schools within a 1 mile buffer of toxic sites are demographically the same as those outside
#how would you go about doing this? We would neet to create 1 mile buffer around the toxic sites.
#let's create a buffer
tox_buf <- st_buffer(tox, dist = 5280) # create an object tox_buf that has a radius of 5280 ft. Why do we use 5280? 1mi=5280 ft. The units of our projection are feet (see summary(tox)).
summary(tox)#see the units of the projection.
plot(tox_buf[1])
plot(tox,add=TRUE)
head(tox_buf)
class(tox_buf)# its a polygon file retaining all aspects of the tox sites on the buffers.
#find the schools that fall in the buffer zones. This works the same way as subseting. Just as data[1:5,] gives you the first 5 rows of a data, data[buffer,] gives you the data that falls inside the buffer
sch_1tox <- st_filter(sch, tox_buf) #sch_1tox contains only the schools in the buffer
dim(sch)
dim(sch_1tox) #Look at the dimensions of the data. There are 94 schools in the toxic 1 mile buffer
plot(sch_1tox)# plots only the 94 schools affected
names(sch)
plot(tox_buf,add=TRUE,border=8)
#create a separate data for the schools outside of the buffer
#note that:
ggplot() +
geom_sf(data = tox_buf, fill = "red") +
geom_sf(data = sch) +
geom_sf(data = sch_1tox, color = "green")
sch_1tox$ORG_NUM#is the unique IDs for the schools in the 1 mile buffer
sch$ORG_NUM# are the unique IDs for all schools.
sch$ORG_NUM %in% sch_1tox$ORG_NUM# returns TRUE for schools in sch that are also in sch_1tox
!sch$ORG_NUM %in% sch_1tox$ORG_NUM# takes the negation of the above (returns FALSE where the above was TRUE, returns TRUE where the above was false)
#in other words, it returs true for schools that are not in the 1 mile toxic buffer (sch_1tox). See simple example below.
#list1 %in% list2
##----------------
#Subsetting example ...
#example ....
c(3,4,5,6,7) %in% c(5,6)#returs TRUE for list1 items that are in list2
!c(3,4,5,6,7) %in% c(5,6)#does the opposite
c(3,4,5,6,7)[c(3,4,5,6,7) %in% c(5,6)]#subsets list1 that are in list2
c(3,4,5,6,7)[!c(3,4,5,6,7) %in% c(5,6)]#subset list1 that are not in list2
##----------------
#lets apply that to the tox data
sch_o1tox<-sch[!sch$ORG_NUM %in% sch_1tox$ORG_NUM,] # the comma before ] is needed becuase you are subsetting a data frame that has two dimensions. For vectors, you wouldn't need it as in the numeric example anove.
dim(sch_o1tox)#look at the dimensions. 376 schools are outside of the buffers
plot(sch_o1tox,col=3,add=TRUE)
plot(tox_buf,add=TRUE)
# Categorize whether school falls within buffer
sch_tox_test <- sch %>%
mutate("tox_status" = ifelse(lengths(st_intersects(., tox_buf)) > 0, TRUE, FALSE)) %>%
st_drop_geometry() %>%
tabyl(tox_status)
############################################
#We now have two data sets for the in buffer and out of buffer data. I will create a data.frame for each for ease of manipulation.
#compare the sociodemographics of the two groups of schools
d1<-as.data.frame(sch_1tox)#schools in buffer
d2<-as.data.frame(sch_o1tox)#schools outside of buffer
#note the missing values
#I will treat missingness as missing at random and exclude these observations from the data.
d1<-na.omit(d1)#creates a data d1 without the missing values in d1.
d2<-na.omit(d2)#creates a data d1 without the missing values in d2.
dim(d1)
dim(d2)
summary(d1)#the summary shows that somme of the school demographic data is missing (NA is missing)
summary(d2)
head(d1)#see the first few rows of d1
#We are interested in comparing the values in columns 5-10 in each data set.
#Take the total sum of students in each column and compare proportions of students in and outside of the buffer.
apply(d1[,5:10],2,sum)#takes data d1 columns 5 through 10, and by column (2 tells it to do the operation by column), applies the sum function. If you had wanted the operation to be done by row, you would use 1 instead of 2.
apply(d2[,5:10],2,sum)
#Create a new data frame with these two results, usin each result as a row.
# rbind(c(1,2,3),c(4,5,6))#run this code to see what rbind does
# data.frame(rbind(c(1,2,3),c(4,5,6)))#run this code to see what data.frame does
#create a data frame with each row correspondeing to in
t1<-data.frame(rbind(
apply(d1[,5:10],2,sum),
apply(d2[,5:10],2,sum)
))
##
t1#see t1
row.names(t1)<-c("in_buffer","outside_buffer")#create row names for the data
t1
#names(t1)<-c("All","Black","LowIncome","Hispanic","Asian","White")#update the column names with more intuitive names
#t1
#lets get the column totals for total student in each group.
coltot<-apply(t1,2,sum)
#Transpose the t1 data
t(t1)#transposes t1 (makes the rows into columns)
#Divide the transposed data by coltot (if you don't transpose, the dividsion will not work. Try it and see the results). YOu cal also just copy t1 to a spreadsheet and compute the percentages.
t(t1)/coltot
#the above output gives us the percentaes of each category that is in and outside of the toxic buffer. 18.6% of all students are in the buffer. 13.0% of black students are in the buffer. As compared to all studenst, black students tend to be less likely to be in the toxic buffer. If we look at the Hispanic student proportion, 24.6% are in the buffer as compared to 18.6% for all studnets. It suggests that Hispanc students tend to be within these buffers more so than other students. We can more formally test these using a Chi-squared test.
#let's define some additional columns
t1$n_other<-t1$n_all-t1$n_black-t1$n_white-t1$n_asian#other_race
t1$n_nonHispanic<-t1$n_all-t1$n_hispanic#hispanic/non-hispanic
t1$n_nonLowInc<-t1$n_all-t1$n_lowInc#lowincome/non-lowincome
t1#see t1
#lets define three contingency tables
tRace<-t1[,c(2,5,6,7)]#table in/out buffer BY Race
tHisp<-t1[,c(4,8)]#table in/out buffer BY ethnicity/Hispanic
tEcon<-t1[,c(3,9)]#table in/out buffer BY Income
#let's check we have the correct columns
tRace
tHisp
tEcon
source("chitest.R")# read in the chitest function
#We can also do a Chi-sqare test, but because there is double counting in the categories, we have to be careful and define categories that are mutually exclusive. Create the following columns in t1.
chitest(tRace)
chitest(tHisp)
chitest(tEcon)
dist1<-spDists(sch_1tox,tox)#create a distance matrix between schools in the 1 mile buffer and the toxic sites
class(dist1)#dist 1 is a matrix
dim(dist1)#its dimension is 94 (the number of schools) by 78 (the number of toxic sites)
dist1[1:10,1:10]# shows the first 10 rows and 10 columns of dist1. Distances are measured in feet. Each row is a school and distances show the how far it is to toxic site 1, toxic site 2, etc.
#We are going to assume that only toxic sites within 1 mile of schools are important. Lets put 0 where distaneces are greater than a mile.
dist2<-ifelse(dist1>5280,0,dist1)#create dist2 which replaces distances longer than a mile with 0
dist2[1:10,1:10]#see dist2
dist1<-spDists(sch_1tox,tox)#create a distance matrix between schools in the 1 mile buffer and the toxic sites
st_filter(sch, tox_buf)
